{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse.linalg import svds\n",
    "from tqdm import tqdm\n",
    "import recs.path as path\n",
    "from recs.cf import CollaborativeFiltering, generate_cf_predict_df\n",
    "from recs.util import id2cat, recall_evaluate, readjson2dict, save2json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preload    \n",
    "u2idx = readjson2dict(\"crm_idx\")\n",
    "i2idx = readjson2dict(\"fund_info_idx\")\n",
    "fund_info_web_path = os.path.join(path.data_path, \"fund_info_web.pkl\")\n",
    "crm_path = os.path.join(path.data_path, \"crm.pkl\")\n",
    "trans_buy_path = os.path.join(path.data_path, \"trans_buy.pkl\")\n",
    "\n",
    "\n",
    "fund_info_web = pd.read_pickle(fund_info_web_path)\n",
    "fund_info_web = fund_info_web[fund_info_web.fund_id.isin(i2idx.keys())]\n",
    "fund_info_web.fund_id = fund_info_web.fund_id.apply(lambda x: i2idx[x])\n",
    "crm = pd.read_pickle(crm_path)\n",
    "\n",
    "exist_funds = fund_info_web.fund_id.unique().tolist()\n",
    "\n",
    "trans_buy_df = pd.read_pickle(trans_buy_path)\n",
    "trans_buy_df = trans_buy_df[trans_buy_df.fund_id.isin(exist_funds)]\n",
    "\n",
    "user_trade_freq = trans_buy_df.id_number.value_counts().index.tolist()\n",
    "\n",
    "groups_index = []\n",
    "groups_index.append([0, 527])\n",
    "groups_index.append([528, 3760])\n",
    "groups_index.append([3761, 38181])\n",
    "groups_index.append([38182, len(user_trade_freq)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_period = [201400, 202100]\n",
    "bestsel_period = [201900, 202100]\n",
    "target_user_date = 202012\n",
    "\n",
    "trans_buy = trans_buy_df.copy()\n",
    "# training\n",
    "train_df = trans_buy[\n",
    "    (trans_buy.buy_date < history_period[1]*100) &\n",
    "    (trans_buy.buy_date > history_period[0]*100) \n",
    "]\n",
    "\n",
    "best_selling_funds = trans_buy_df[\n",
    "            (trans_buy_df.buy_date > bestsel_period[0]*100) &\n",
    "            (trans_buy_df.buy_date < bestsel_period[1]*100)\n",
    "        ].fund_id.value_counts().index.to_series()\n",
    "\n",
    "trans_buy = trans_buy_df.copy()\n",
    "# training\n",
    "train_df = trans_buy[\n",
    "    (trans_buy.buy_date < history_period[1]*100) &\n",
    "    (trans_buy.buy_date > history_period[0]*100) \n",
    "]\n",
    "train_df = train_df.groupby([\"id_number\", \"fund_id\"]).size().reset_index(name=\"Time\")\n",
    "best_selling_num = 50\n",
    "if (best_selling_num != -1):\n",
    "    best_selling_exist_funds = list(set(exist_funds) & set(best_selling_funds.tolist()[:best_selling_num]))\n",
    "else:\n",
    "    best_selling_exist_funds = list(set(exist_funds))\n",
    "\n",
    "train_df = train_df[train_df.fund_id.isin(best_selling_exist_funds)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2936    5626\n",
       "3197    3932\n",
       "2940    3624\n",
       "2099    3193\n",
       "2485    3137\n",
       "2541    3049\n",
       "2416    2921\n",
       "3215    2760\n",
       "2518    2628\n",
       "722     2264\n",
       "2274    2262\n",
       "3130    2174\n",
       "1251    2136\n",
       "2135    2098\n",
       "1790    2062\n",
       "2301    1924\n",
       "2717    1851\n",
       "3072    1751\n",
       "3039    1746\n",
       "2516    1710\n",
       "2131    1687\n",
       "3196    1405\n",
       "995     1310\n",
       "926     1221\n",
       "2971    1188\n",
       "2730    1111\n",
       "2313    1102\n",
       "1791    1026\n",
       "921      984\n",
       "20       974\n",
       "603      969\n",
       "3133     967\n",
       "2489     963\n",
       "2268     949\n",
       "1838     933\n",
       "1839     931\n",
       "1461     926\n",
       "1579     909\n",
       "1580     838\n",
       "1235     800\n",
       "3065     761\n",
       "2904     743\n",
       "2897     742\n",
       "1167     738\n",
       "3066     730\n",
       "3042     663\n",
       "985      662\n",
       "2145     635\n",
       "2908     595\n",
       "21       577\n",
       "Name: fund_id, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.fund_id.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_ID = \"id_number\"\n",
    "ITEM_ID = \"fund_id\"\n",
    "RATE_KEY = \"Time\"\n",
    "\n",
    "\n",
    "class PMF(nn.Module):\n",
    "    def __init__(self, num_users, num_items, emb_size, lam_u, lam_v):\n",
    "        super(PMF, self).__init__()\n",
    "        self.user_emb = nn.Embedding(num_users, emb_size)\n",
    "        self.item_emb = nn.Embedding(num_items, emb_size)\n",
    "        \n",
    "        nn.init.normal_(self.user_emb.weight)\n",
    "        nn.init.normal_(self.item_emb.weight)\n",
    "        \n",
    "        self.user_emb.weight.mul(0.1)\n",
    "        self.item_emb.weight.mul(0.1)\n",
    "        \n",
    "        self.lam_u = lam_u\n",
    "        self.lam_v = lam_v\n",
    "    def forward(self, u, v):\n",
    "        u = self.user_emb(u)\n",
    "        v = self.item_emb(v)\n",
    "        output = (u*v).sum(1)\n",
    "        \n",
    "        # Frobenius norm\n",
    "        u_reg = self.lam_u * torch.sum(u**2)\n",
    "        v_reg = self.lam_v * torch.sum(v**2)\n",
    "        \n",
    "        return output, u_reg, v_reg\n",
    "\n",
    "def train_epocs(model, train_df, epochs=10000, lr=0.01, wd=0.0):\n",
    "    \n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "    model.train()\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        user_tensor = torch.LongTensor(train_df[USER_ID].values).cuda()\n",
    "        item_tensor = torch.LongTensor(train_df[ITEM_ID].values).cuda()\n",
    "        ratings = torch.FloatTensor(train_df[RATE_KEY].values).cuda()\n",
    "        \n",
    "        pred, u_reg, v_reg = model(user_tensor, item_tensor)\n",
    "        loss = F.mse_loss(pred, ratings) + u_reg + v_reg\n",
    "        if epoch % 1000 == 0:\n",
    "            print(f\"Epoch: {epoch}, Loss:{loss}\")\n",
    "            \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80887\n",
      "80887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/10000 [00:00<05:05, 32.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss:1614499.625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1008/10000 [00:28<03:32, 42.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1000, Loss:5.982850074768066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2008/10000 [00:51<03:09, 42.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2000, Loss:5.728758811950684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3004/10000 [01:16<03:29, 33.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3000, Loss:5.729884624481201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4008/10000 [01:46<02:24, 41.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4000, Loss:5.731063365936279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5008/10000 [02:10<01:59, 41.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5000, Loss:5.7332072257995605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6008/10000 [02:33<01:34, 42.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6000, Loss:5.7359514236450195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7008/10000 [02:57<01:10, 42.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7000, Loss:5.739982604980469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8003/10000 [03:20<00:48, 40.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8000, Loss:5.744726181030273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9007/10000 [03:44<00:23, 42.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9000, Loss:5.750947952270508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [04:07<00:00, 40.32it/s]\n"
     ]
    }
   ],
   "source": [
    "num_users = len(train_df[USER_ID])\n",
    "num_items = len(train_df[ITEM_ID])\n",
    "print(num_users)\n",
    "print(num_items)\n",
    "model = PMF(num_users, num_items, emb_size=1000, lam_u=0.01, lam_v=0.01).cuda()\n",
    "train_epocs(model, train_df=train_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49721"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_users_id = crm[crm.yyyymm == target_user_date].id_number.unique().tolist()\n",
    "target_users_id[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79848/79848 [02:21<00:00, 562.39it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    \n",
    "available_users = train_df.id_number.unique().tolist()\n",
    "\n",
    "rec_dict = {}\n",
    "\n",
    "items = torch.tensor(\n",
    "        train_df[ITEM_ID].unique().tolist()\n",
    "    ).cuda()\n",
    "\n",
    "for user in tqdm(target_users_id):    \n",
    "    ignore_item = trans_buy_df[\n",
    "        (trans_buy_df.id_number == user)\n",
    "    ].fund_id.unique().tolist()\n",
    "\n",
    "    user_tensor = torch.tensor([user]).cuda()\n",
    "        \n",
    "    predictions, _, __ = model(user_tensor, items)\n",
    "    predictions = predictions.tolist()\n",
    "    \n",
    "    if (user not in available_users):\n",
    "        rec_dict[str(user)] = best_selling_funds[~best_selling_funds.isin(ignore_item)].tolist()[:10]\n",
    "        continue\n",
    "        \n",
    "    rdict = {\n",
    "        \"items\": items.cpu().numpy().tolist(),\n",
    "        \"recStr\": predictions\n",
    "    }\n",
    "    \n",
    "    rec_df = pd.DataFrame(rdict).sort_values(by=['recStr'], ascending=False)\n",
    "    \n",
    "    rec_df = rec_df[~rec_df[\"items\"].isin(ignore_item)]\n",
    "\n",
    "    rec_dict[str(user)] = rec_df[\"items\"].tolist()[:10] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79848/79848 [05:00<00:00, 265.52it/s]\n"
     ]
    }
   ],
   "source": [
    "len(rec_dict)\n",
    "dec_rec_result = {}\n",
    "for user in tqdm(rec_dict):            \n",
    "    dec_user = id2cat(u2idx, int(user))\n",
    "    dec_funds = []\n",
    "    for item in rec_dict[user]:\n",
    "        dec_funds.append(id2cat(i2idx, item))\n",
    "    dec_rec_result[dec_user] = dec_funds\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/tf/recommenders/export/result/1635653384.0998619.json'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save2json(dec_rec_result, folder='/result')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
